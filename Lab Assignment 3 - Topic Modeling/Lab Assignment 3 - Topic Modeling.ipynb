{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed7fae8-e9a1-4870-b2dc-06e6a48df766",
   "metadata": {},
   "source": [
    "## <center>CISB5123 Text Analytics</center>\n",
    "## <center> Lab Assignment 3 - Topic Modeling </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a36592-4702-45c1-8bdc-d685b97309e3",
   "metadata": {},
   "source": [
    "#### 1) Amirul Farhan bin Kamaruzaman, SW01082374\n",
    "#### 2) Maizatul Aufa binti Zamidi, SW01082394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e567e8f-b7ef-47e9-857d-34da1db9cf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\maiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\maiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For text preprocessing \n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "# For topic modeling \n",
    "from gensim import corpora \n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "import pandas as pd \n",
    "import string\n",
    " \n",
    "# Download NLTK Resources \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8f4732-7fdd-4d21-bf5a-993f4a69aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('news_dataset.csv')\n",
    "df = df[['text']]\n",
    "df.dropna(inplace=True) #remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f576d056-c83f-4233-89fa-866574eea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())  # Lowercase and tokenize\n",
    "    tokens = [token for token in tokens if token.isalpha()]  # Keep only pure words (remove numbers & punctuation)\n",
    "    tokens = [token for token in tokens if token not in stop_words]  # Remove stopwords\n",
    "    tokens = [stemmer.stem(token) for token in tokens]  # Apply stemming\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]  # Apply lemmatization\n",
    "    return tokens\n",
    "\n",
    "#Apply preprocessing\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e59c3d-ffe6-4567-8a69-69d0ebb2b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wonder', 'anyon', 'could', 'enlighten', 'car', 'saw', 'day', 'sport', 'car', 'look', 'late', 'earli', 'call', 'bricklin', 'door', 'realli', 'small', 'addit', 'front', 'bumper', 'separ', 'rest', 'bodi', 'know', 'anyon', 'tellm', 'model', 'name', 'engin', 'spec', 'year', 'product', 'car', 'made', 'histori', 'whatev', 'info', 'funki', 'look', 'car', 'plea']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59220c2a-0104-4957-8592-fdb7b34f2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create document-term matrix\n",
    "dictionary = corpora.Dictionary(preprocessed_documents)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a941a731-bb84-480a-ba99-0d49c8f99f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run LDA\n",
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "143041da-da24-4d54-8c9e-9dc54ce7004b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.6419611361396821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=preprocessed_documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_lda}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e93ef-c03a-4950-9f11-8d3ee94cbcbe",
   "metadata": {},
   "source": [
    "The coherence score of LDA model is 0.6419, which shows that the topics generated are quite interpretable and make sense. Since a score above 0.5 is usually considered good, this means the model did a decent job at goruping related words into meaningful topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5955d88-ae32-461e-8c55-26c087b26bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret Results\n",
    "article_labels = []\n",
    "for doc in preprocessed_documents:\n",
    "    bow = dictionary.doc2bow(doc)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    dominant_topic = max(topics, key=lambda x: x[1])[0]\n",
    "    article_labels.append(dominant_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f852ee02-c079-4b10-a2aa-3dfecc445b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "df_result = pd.DataFrame({\"Article\": df['text'].tolist(), \"Topic\": article_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "405b9962-2911-48f8-b964-a571fb98afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table with Articles and Topic:\n",
      "                                                 Article  Topic\n",
      "0      I was wondering if anyone out there could enli...      2\n",
      "1      I recently posted an article asking what kind ...      2\n",
      "2      \\nIt depends on your priorities.  A lot of peo...      1\n",
      "3      an excellent automatic can be found in the sub...      1\n",
      "4      : Ford and his automobile.  I need information...      1\n",
      "...                                                  ...    ...\n",
      "11091  Secrecy in Clipper Chip\\n\\nThe serial number o...      1\n",
      "11092  Hi !\\n\\nI am interested in the source of FEAL ...      4\n",
      "11093  The actual algorithm is classified, however, t...      1\n",
      "11094  \\n\\tThis appears to be generic calling upon th...      1\n",
      "11095  \\nProbably keep quiet and take it, lest they g...      2\n",
      "\n",
      "[11096 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the DataFrame\n",
    "print(\"Table with Articles and Topic:\")\n",
    "print(df_result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41af6172-d31e-401d-a7c2-07ac267ecdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms for Topic #0:\n",
      "['peopl', 'would', 'one', 'govern', 'god', 'state', 'law', 'say', 'use', 'right']\n",
      "\n",
      "Top terms for Topic #1:\n",
      "['use', 'key', 'encrypt', 'one', 'chip', 'would', 'system', 'get', 'like', 'clipper']\n",
      "\n",
      "Top terms for Topic #2:\n",
      "['go', 'would', 'get', 'one', 'know', 'like', 'think', 'year', 'time', 'peopl']\n",
      "\n",
      "Top terms for Topic #3:\n",
      "['q', 'max', 'g', 'r', 'p', 'n', 'db', 'k', 'w', 'c']\n",
      "\n",
      "Top terms for Topic #4:\n",
      "['x', 'file', 'use', 'program', 'window', 'anonym', 'inform', 'avail', 'post', 'includ']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms for each topic\n",
    "for topic_id in range(lda_model.num_topics):\n",
    "    print(f\"Top terms for Topic #{topic_id}:\")\n",
    "    top_terms = lda_model.show_topic(topic_id, topn=10)\n",
    "    print([term[0] for term in top_terms])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d1af18e-2b25-40ac-af6b-579f91d9bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Terms for Each Topic:\n",
      "Topic 0:\n",
      "- \"peopl\" (weight: 0.009)\n",
      "- \"would\" (weight: 0.008)\n",
      "- \"one\" (weight: 0.007)\n",
      "- \"govern\" (weight: 0.007)\n",
      "- \"god\" (weight: 0.006)\n",
      "- \"state\" (weight: 0.005)\n",
      "- \"law\" (weight: 0.005)\n",
      "- \"say\" (weight: 0.005)\n",
      "- \"use\" (weight: 0.005)\n",
      "- \"right\" (weight: 0.005)\n",
      "\n",
      "Topic 1:\n",
      "- \"use\" (weight: 0.020)\n",
      "- \"key\" (weight: 0.018)\n",
      "- \"encrypt\" (weight: 0.011)\n",
      "- \"one\" (weight: 0.010)\n",
      "- \"chip\" (weight: 0.010)\n",
      "- \"would\" (weight: 0.009)\n",
      "- \"system\" (weight: 0.008)\n",
      "- \"get\" (weight: 0.008)\n",
      "- \"like\" (weight: 0.007)\n",
      "- \"clipper\" (weight: 0.006)\n",
      "\n",
      "Topic 2:\n",
      "- \"go\" (weight: 0.011)\n",
      "- \"would\" (weight: 0.009)\n",
      "- \"get\" (weight: 0.009)\n",
      "- \"one\" (weight: 0.008)\n",
      "- \"know\" (weight: 0.008)\n",
      "- \"like\" (weight: 0.008)\n",
      "- \"think\" (weight: 0.007)\n",
      "- \"year\" (weight: 0.007)\n",
      "- \"time\" (weight: 0.006)\n",
      "- \"peopl\" (weight: 0.006)\n",
      "\n",
      "Topic 3:\n",
      "- \"q\" (weight: 0.099)\n",
      "- \"max\" (weight: 0.086)\n",
      "- \"g\" (weight: 0.056)\n",
      "- \"r\" (weight: 0.055)\n",
      "- \"p\" (weight: 0.047)\n",
      "- \"n\" (weight: 0.044)\n",
      "- \"db\" (weight: 0.041)\n",
      "- \"k\" (weight: 0.031)\n",
      "- \"w\" (weight: 0.031)\n",
      "- \"c\" (weight: 0.030)\n",
      "\n",
      "Topic 4:\n",
      "- \"x\" (weight: 0.033)\n",
      "- \"file\" (weight: 0.016)\n",
      "- \"use\" (weight: 0.015)\n",
      "- \"program\" (weight: 0.011)\n",
      "- \"window\" (weight: 0.009)\n",
      "- \"anonym\" (weight: 0.008)\n",
      "- \"inform\" (weight: 0.008)\n",
      "- \"avail\" (weight: 0.007)\n",
      "- \"post\" (weight: 0.007)\n",
      "- \"includ\" (weight: 0.007)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the top terms for each topic with weight\n",
    "print(\"Top Terms for Each Topic:\")\n",
    "for idx, topic in lda_model.print_topics():\n",
    "    print(f\"Topic {idx}:\")\n",
    "    terms = [term.strip() for term in topic.split(\"+\")]\n",
    "    for term in terms:\n",
    "        weight, word = term.split(\"*\")\n",
    "        print(f\"- {word.strip()} (weight: {weight.strip()})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc65f7-0b21-4ab2-94c4-36be72cf8550",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
