{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "478a72ad-3825-42b7-9cea-1d325fca4462",
   "metadata": {},
   "source": [
    "### <center><b> CISB123 Text Analytics </b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9dbca-f74a-467d-8528-00d8a06e9edc",
   "metadata": {},
   "source": [
    "## <center><b> Lab 8 - Text Clustering using TF-IDF Vectorizer </b><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c64083-b7ef-4eae-bc32-7311a6c85cb0",
   "metadata": {},
   "source": [
    "### Name: Maizatul Aufa binti Zamidi (SW01082394)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa9322-312e-41fd-8588-d8a4ab1fbf14",
   "metadata": {},
   "source": [
    "##### TEXT CLUSTERING USING TF-IDF VECTORIZER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1d4bc0-5381-40da-aca1-22e5c92f887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from tabulate import tabulate \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e5e2b6-1d53-41ca-8101-3a1db7ef7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I love playing football on the weekends\", \n",
    "           \"I enjoy hiking and camping in the mountains\", \n",
    "           \"I like to read books and watch movies\", \n",
    "           \"I prefer playing video games over sports\", \n",
    "           \"I love listening to music and going to concerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b9dc1e-c895-4301-9377-5b5178d032b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa98277c-7775-46de-9302-28fd96af1580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9949af11-c286-4222-864c-a40ed5846ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(doc):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stemmer = PorterStemmer()\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub(r'[^a-z\\s]', '', doc)\n",
    "    tokens = doc.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f829850-460e-4b41-963a-461c825cd6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "preprocessed_dataset = [preprocess_text(doc) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ad14a5-7d21-406e-988a-2f7c7c9b644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_dataset)\n",
    "\n",
    "k = 2\n",
    "km = KMeans(n_clusters=k, random_state=42)\n",
    "km.fit(X)\n",
    "y_pred = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bef9023-a434-4b3b-b9bf-ffa62a036486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        0\n",
      "I like to read books and watch movies                              1\n",
      "I prefer playing video games over sports                           1\n",
      "I love listening to music and going to concerts                    1\n"
     ]
    }
   ],
   "source": [
    "# Display the document and its predicted cluster in a table \n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]] \n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)]) \n",
    "print(tabulate(table_data, headers=\"firstrow\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce22818-8fdf-4aae-aa14-f15526b1dc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      "Cluster 1:\n",
      " love\n",
      "\n",
      " play\n",
      "\n",
      " footbal\n",
      "\n",
      " weekend\n",
      "\n",
      " go\n",
      "\n",
      " sport\n",
      "\n",
      " music\n",
      "\n",
      " concert\n",
      "\n",
      " video\n",
      "\n",
      " game\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms per cluster \n",
    "print(\"\\nTop terms per cluster:\") \n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "terms = vectorizer.get_feature_names_out() \n",
    "for i in range(k): \n",
    "    print(\"Cluster %d:\" % i) \n",
    "for ind in order_centroids[i, :10]: \n",
    "    print(' %s' % terms[ind]) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9279f11f-f77b-49aa-948f-963b517a3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity \n",
    "total_samples = len(y_pred) \n",
    "cluster_label_counts = [Counter(y_pred)] \n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples \n",
    "print(\"Purity:\", purity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997d473-cb23-491e-a9c0-03cc43a5db8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b07172-93c0-417b-b7ec-a01f62e381e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
